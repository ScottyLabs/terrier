# RFC 0002: Development Environment & CI

- **Status:** Accepted
- **Author(s):** @ap-1 
- **Created:** 2026-02-09  
- **Updated:** 2026-02-09

## Overview

This RFC defines the development environment setup and CI/CD strategy for Terrier. It covers local development tooling (devenv, direnv, process-compose), required services for development, Nix installation requirements, and the CI pipeline using Garnix on our GitHub mirror with container publishing to Codeberg's registry.

## Motivation

A well-defined development environment is critical for:

- Reducing onboarding friction for new contributors
- Ensuring consistency across team members' local setups
- Matching production dependencies and configurations
- Lowering the barrier to contributing to ScottyLabs' broader Nix infrastructure
- Building CI/CD muscle for our NixOS deployment infrastructure

The choice of Nix-based tooling also serves a pedagogical purpose: since ScottyLabs deploys on NixOS VMs and Terrier itself will be deployed via Nix, having contributors comfortable with Nix reduces friction when bumping package versions (e.g., Keycloak in nixpkgs) or contributing to other DevOps repositories.

## Goals

- Provide a reproducible development environment across macOS, Linux, and WSL
- Minimize time from git clone to running application
- Run all backend services locally without manual setup
- Share Nix configuration between development and CI
- Fast CI builds with effective caching
- Automatic container image builds and publishing
- Make Nix adoption reversible (provide clear uninstall path)

## Non-Goals

- Supporting Windows native development (WSL only)
- Building a custom CI platform
- Supporting multiple development environment options, like Docker Compose or Dev Containers

## Detailed Design

### Development Environment

**Core tooling:**

- **devenv**: Declarative dev environment manager
- **direnv**: Automatic environment activation on cd
- **process-compose**: Service orchestration for local development

We use a standalone `devenv.nix` file rather than integrating devenv into `flake.nix` via the flake module. The devenv documentation explicitly recommends this approach: when integrated into flakes, devenv provides only a "stripped down version" with reduced features and performance limitations. The hybrid approach gives us:

- Full devenv feature set (not just `up` and `shell` subcommands)
- Version-locked devenv per project (via flake.nix providing the devenv binary)
- Best performance for daily development

**Directory structure:**

```
/
├── .devenv/                # devenv state (gitignored)
├── .direnv/                # direnv state (gitignored)
├── .envrc                  # direnv: auto-loads devenv
├── .pre-commit-config.yaml # Autogenerated pre-commit hooks configuration (gitignored)
├── flake.lock              # Locked dependencies
├── flake.nix               # Nix flake: packages, devenv binary
└── devenv.nix              # Development environment config
```

**Services in development:**

All services run via process-compose defined in devenv.nix:

1. **PostgreSQL** (primary database)
   - Initialized with development schema
   - Accessible at localhost:5432, local connection via Unix socket
   - Database migrations run automatically via sea-orm in main.rs at startup

2. **pgAdmin** (database GUI)
   - Web interface for database inspection
   - Pre-configured connection to local Postgres

3. **Valkey** (Open-source Redis fork - sessions, cache, pub/sub)
   - Accessible at localhost:6379

4. **MinIO** (S3-compatible object storage)
   - Local S3 for file uploads
   - MinIO Console enabled for browsing buckets

**Non-local services:**

For auth, the application will point to the ScottyLabs Keycloak instance, using the terrier-dev client in the terrier realm. We won't use a local Keycloak instance for development since it's heavy and slow to start up. Development mode will log outgoing emails to stdout rather than sending them. We won't use a mock SMTP server locally for the same reason.

### Nix Installation Requirements

We encourage contributors to use the [Determinate Systems Nix installer](https://github.com/DeterminateSystems/nix-installer) rather than the official Nix installer. Reasons:

1. Provides a working uninstaller (official Nix has problematic uninstall)
2. Better defaults for Flakes and nix-command

This keeps the barrier to entry low - contributors know they can fully remove Nix if they decide it's not for them.

**Setup guides:**

We'll provide comprehensive setup documentation for:

- macOS (Apple Silicon)
- Linux (NixOS)
- Windows via WSL2 (Ubuntu)

Each guide covers:

1. Installing Determinate Systems Nix
2. Installing direnv
3. Cloning repo and first-time setup (running `direnv allow`)
4. Running the development environment
5. Uninstalling Nix if needed

### CI Strategy

**Platform:**

We use Garnix for CI rather than GitHub Actions or Forgejo Actions. Garnix has the following advantages:

- 2-10x faster than GitHub Actions
- Free tier: 1,500 CI minutes/month
- Zero-configuration Nix caching (content-addressed, globally deduplicated)
- No special cache setup required
- Cache shared between all garnix users (if someone built a derivation, you get it)
- Works with the GitHub mirror without compromising Codeberg as primary

We keep our existing self-hosted Forgejo runners available for Codeberg-specific workflows if needed.

**Workflow:**

1. Code pushed to Codeberg (primary)
2. Codeberg auto-mirrors to GitHub, which is a given
3. GitHub webhook triggers Garnix
4. Garnix builds on Garnix's servers
5. Results cached at cache.garnix.io
6. Status posted to GitHub
7. Garnix pushes container images directly to Codeberg registry

Garnix automatically evaluates the flake and builds:

- All packages (backend, frontend, containers)
- All checks (tests, lints, formatting)
- All devShells (to verify dev environment works)

We can customize what builds via optional `garnix.yaml` config file.

**Garnix cache configuration:**

The garnix cache is configured in `flake.nix` using the `nixConfig` attribute, which prompts users to accept the cache on first use:

```nix
{
  nixConfig = {
    extra-substituters = [ "https://cache.garnix.io" ];
    extra-trusted-public-keys = [ "cache.garnix.io:CTFPyKSLcx5RMJKfLo5EEPUObbA78b0YQ2DTCJXqr9g=" ];
  };
  
  inputs = {
    nixpkgs.url = "github:cachix/devenv-nixpkgs/rolling";
    devenv.url = "github:cachix/devenv";
  };
  
  outputs = { ... };
}
```

When developers first run `nix develop` or `devenv shell`, they'll be prompted to trust the cache. Once accepted, anything built in CI is instantly available locally with no rebuilding.

NixOS users can optionally add the cache system-wide in their configuration:

```nix
nix.settings = {
  extra-substituters = [ "https://cache.garnix.io" ];
  extra-trusted-public-keys = [ "cache.garnix.io:CTFPyKSLcx5RMJKfLo5EEPUObbA78b0YQ2DTCJXqr9g=" ];
};
```

### Container Building and Publishing

**Container creation:**

We use `nix2container` rather than `dockerTools.buildImage` for significantly faster rebuild/push cycles. The container is defined in flake.nix outputs:

```nix
packages.x86_64-linux.container = 
  nix2container.buildImage {
    name = "terrier";
    config = {
      entrypoint = ["${self.packages.x86_64-linux.backend}/bin/terrier"];
    };
    layers = [
      (nix2container.buildLayer { 
        deps = [ /* runtime dependencies */ ]; 
      })
    ];
  };
```

**Note:** There is only one container. The backend serves the frontend in production (as opposed to development, which uses the Vite dev server + HMR). The container includes both the Rust backend binary and the built frontend assets.

Additional benefits of nix2container:
- Doesn't write tarballs to /nix/store
- Skips already-pushed layers and deduplicates them

**Registry:**

We publish containers to Codeberg's container registry at `codeberg.org/scottylabs/terrier`. This keeps artifacts aligned with the primary repository on Codeberg.

Images are pulled in docker-compose.yml as:

```yaml
services:
  terrier:
    image: codeberg.org/scottylabs/terrier:latest
```

**Publishing workflow:**

Garnix builds container images and pushes directly to Codeberg registry. This requires configuring Garnix with:

- Codeberg registry credentials (PAT or service account)
- Push action configured to target `codeberg.org/scottylabs/terrier`

Details of exact Garnix configuration will be determined during implementation.

**Codeberg storage quotas:**

Codeberg has default storage limits (750 MiB git, 1.5 GB LFS, separate container registry limits). Container images will likely exceed defaults quickly. Codeberg's philosophy: "We will grant every project the resources it needs, provided that we can afford them... there is no quota for valid use-cases."

When we reach halfway to storage limits, we'll submit an exception request via https://codeberg.org/Codeberg-e.V./requests with:

- Project description (AGPL-3.0 hackathon platform)
- Use case (self-hostable product, distributing containers)
- Estimated needs (container images with multiple release tags)
- ScottyLabs/CMU context

Terrier fits exactly the kind of FOSS project Codeberg wants to support, so approval is expected. Otherwise, we can explore alternative hosting solutions.

### Git Hooks

Pre-commit hooks managed via devenv's pre-commit integration. Hooks are defined in devenv.nix:

- `nixpkgs-fmt` - Nix code formatting
- `clippy` - Rust linting
- `biome` - Frontend linting and formatting (TypeScript, Svelte, JSON, etc.)
- `cargo test` - Tests before commit

**Note on frontend tooling:** We currently use Biome for frontend linting and formatting. We may switch to oxc (oxlint/oxfmt) in the future once it has better Svelte support.

Hooks are automatically installed when entering the dev environment. The same checks run in CI, ensuring consistency.

## Alternatives Considered

### Development Environment Alternatives

**Docker Compose for development:**

Many projects use Docker Compose for local development. We rejected this because:

- Doesn't help contributors learn Nix (our deployment target)
- Separate configuration from production (more to maintain)
- Slower startup than process-compose
- Doesn't integrate with our NixOS infrastructure

We're making a pedagogical choice: by having contributors use Nix for development, they're better equipped to contribute to ScottyLabs' broader infrastructure and understand Terrier's deployment.

**devenv integrated into flake.nix:**

We could use devenv's flake module to integrate everything into flake.nix. We chose a separate devenv.nix because:

- devenv documentation explicitly recommends standalone for best experience
- Flake integration provides "stripped down version" with limited features
- Performance is worse when integrated
- Complexity of flake.nix would increase

**Multiple environment options:**

We could support multiple dev environment setups (Docker, Nix, manual). We chose to standardize on Nix because:

- ScottyLabs has a fleet of NixOS VMs, so contributors will encounter Nix anyway
- Multiple options means multiple things to maintain
- Nix provides the best match to production
- Better to have one well-documented path than several mediocre ones

### CI Alternatives

**GitHub Actions:**

The obvious choice given our GitHub mirror. We chose Garnix instead because:

- Garnix is 2-10x faster (benchmarked)
- Zero-configuration caching (no Cachix setup, no magic-nix-cache config)
- Global cache means maximum reuse across all garnix users
- Still posts status to GitHub

**Forgejo Actions only, with self-hosted cache:**

We could run everything on our self-hosted Forgejo runners and self-hosted cache. We chose Garnix + its cache instead because:

- We don't have to deploy Attic or Harmonia
- Garnix cache is globally shared 
- Faster builds than setting up our own cache

**Codeberg Registry vs. ghcr.io vs. Docker Hub:**

We considered publishing containers to GitHub Container Registry or Docker Hub. We chose Codeberg registry because:

- Keeps artifacts with primary repository
- Philosophically consistent (don't strengthen GitHub's network effects)
- Codeberg supports FOSS projects generously

ghcr.io would be simpler (no exception request needed) but compromises our principle of keeping infrastructure on Codeberg where practical.

## Open Questions

1. **Valkey GUI:** Do we include Redis Commander in process-compose, or is valkey-cli sufficient for development? Trade-off is convenience vs. lighter dev environment.

2. **Garnix -> Codeberg registry:** What's the exact configuration for Garnix to push directly to Codeberg registry? Need to verify Garnix supports this or if we need a Forgejo Action bridge.

3. **Container tagging strategy:** Do we tag with git commit SHA, semantic version, both? How do we handle `latest` tag?

## Implementation Phases

### Development Environment Setup

- Create devenv.nix with all services (Postgres, pgAdmin, Valkey, MinIO)
- Configure process-compose for service orchestration
- Add .envrc for direnv integration
- Test on macOS, Linux, WSL
- Write setup guides for each platform
- Configure git hooks via pre-commit (nixpkgs-fmt, clippy, biome, cargo test)

### CI Configuration

- Install Garnix GitHub App on scottylabs/terrier mirror
- Add garnix.yaml if we need custom build configuration
- Verify CI builds packages, checks, devShells
- Add garnix cache to flake.nix nixConfig
- Test cache hit rates and build times

### Container Publishing

- Define container using nix2container in flake.nix
- Configure Garnix to push to Codeberg registry
- Test end-to-end: code push -> mirror -> garnix -> registry
- Update docker-compose.yml to pull from Codeberg
- Document container publishing workflow
